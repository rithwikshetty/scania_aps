{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1( x ):\n",
    "    \"\"\"\n",
    "    This function performs data preprocessing \n",
    "    and makes final predictions and\n",
    "    returns the class labels\n",
    "    \"\"\" \n",
    "    \n",
    "    # Load preprocessing models\n",
    "    median_imputer = joblib.load(\"../median_imputer.pkl\")\n",
    "    mice_imputer = joblib.load(\"../mice_imputer.pkl\")\n",
    "    \n",
    "    # Drop features with max null values\n",
    "    x = x.drop(['br_000', 'bq_000', 'bp_000', 'bo_000', 'ab_000', 'cr_000', 'bn_000', 'cd_000'] , axis=1)\n",
    "    \n",
    "    # Specify features whose missing values are imputed using Median Imputer\n",
    "    median_features = ['ak_000','ca_000','dm_000','df_000','dg_000', \\\n",
    "                       'dh_000','dl_000','dj_000','dk_000','eb_000', \\\n",
    "                       'di_000','ac_000','bx_000','cc_000']\n",
    "    \n",
    "    # Median Imputation\n",
    "    x[median_features] = median_imputer.transform(x[median_features])\n",
    "    \n",
    "    # MICE Imputation\n",
    "    x = pd.DataFrame(data = mice_imputer.transform(x) , columns= x.columns )\n",
    "    \n",
    "    # Load our Best Model\n",
    "    model = joblib.load(\"../gbdt_model.pkl\")\n",
    "    \n",
    "    # Predict class label \n",
    "    y = model.predict(x)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2( x , y ):\n",
    "    \"\"\"\n",
    "    This function performs data preprocessing, \n",
    "    makes final predictions and returns the computed\n",
    "    performance metric and class labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load preprocessing models\n",
    "    median_imputer = joblib.load(\"../median_imputer.pkl\")\n",
    "    mice_imputer = joblib.load(\"../mice_imputer.pkl\")\n",
    "    \n",
    "    # Drop features with max null values\n",
    "    x = x.drop(['br_000', 'bq_000', 'bp_000', 'bo_000', 'ab_000', 'cr_000', 'bn_000', 'cd_000'] , axis=1)\n",
    "    \n",
    "    # Specify features whose missing values are imputed using Median Imputer\n",
    "    median_features = ['ak_000','ca_000','dm_000','df_000','dg_000', \\\n",
    "                       'dh_000','dl_000','dj_000','dk_000','eb_000', \\\n",
    "                       'di_000','ac_000','bx_000','cc_000']\n",
    "    \n",
    "    # Median Imputation\n",
    "    x[median_features] = median_imputer.transform(x[median_features])\n",
    "    \n",
    "    # MICE Imputation\n",
    "    x = pd.DataFrame(data = mice_imputer.transform(x) , columns= x.columns )\n",
    "    \n",
    "    # Load our Best Model\n",
    "    model = joblib.load(\"../gbdt_model.pkl\")\n",
    "    \n",
    "    # Predict Class Labels\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # Return Performance Metric\n",
    "    return f1_score(y,y_pred,average='macro') , y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing both functions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../aps_failure_test_set.csv\",skiprows=20,na_values=[\"na\"])\n",
    "\n",
    "def get_correct_label(y):\n",
    "    \"\"\"\n",
    "    This function converts the class labels\n",
    "    from 'neg' and 'pos' to 0 and 1 respectively\n",
    "    \"\"\"\n",
    "    return y.replace(['neg','pos'],[0,1])\n",
    "\n",
    "print(data['class'].unique())\n",
    "data['class'] = get_correct_label(data['class'])\n",
    "print(data['class'].unique())\n",
    "\n",
    "y_test = data['class']\n",
    "x_test = data.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1 Score:  0.8817895552269138\n"
     ]
    }
   ],
   "source": [
    "F1_test , y_pred = final_fun_2(x_test,y_test)\n",
    "print(\"Macro-F1 Score: \",F1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
